{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 객체 추적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "동영상에서 지속적으로 움직이는 객체를 찾는 방법을 객체 추적이라고 합니다.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배경 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "동영상 지속적으로 움직이는 객체를 찾는 방법을 객체 추적이라고 합니다.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "배경 제거 함수\n",
    "배경 제거를 구현하는 객체 생성 함수는 아래와 같습니다.\n",
    "\n",
    "cv2.bgsegm.createBackgroundSubtractorMOG(history, nmixtures, backgroundRatio, noiseSigma)\n",
    "history=200: 히스토리 길이\n",
    "nmixtures=5: 가우시안 믹스처의 개수\n",
    "backgroundRatio=0.7: 배경 비율\n",
    "noiseSigma=0: 노이즈 강도 (0=자동)\n",
    "이는 2001년 KadewTraKuPong과 Bowde의 논문(An improved adaptive background mixture model for real-time tracking with shadow detection)에 소개된 알고리즘을 구현한 함수입니다. 여러 가지 파라미터가 있지만 default 값으로 설정해도 됩니다. 추가 튜닝이 필요 없는 이상 아래의 apply() 함수 호출만으로 결과를 얻을 수 있습니다. 배경 제거 객체의 인터페이스 함수는 다음 두 가지가 있습니다.\n",
    "\n",
    "foregroundmask = backgroundsubtractor.apply(img, foregroundmask, learningRate)\n",
    "img: 입력 영상\n",
    "foregroundmask: 전경 마스크\n",
    "learningRate=-1: 배경 훈련 속도(0~1, -1: 자동)\n",
    "backgroundImage = backgroundsubtractor.getBackgroundImage(backgroundImage)\n",
    "backgroundImage: 훈련용 배경 이미지\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np , cv2\n",
    "\n",
    "cap = cv2.VideoCapture('C:/cdd/street.mp4')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기\n",
    "delay = int(1000/fps)\n",
    "\n",
    "# 배경 제거 객체 생성\n",
    "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "while cap.isOpened() :\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # 배경 제거 마스크 계산\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('bgsub',fgmask)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('bgsub',fgmask)\n",
    "    if cv2.waitKey(1) & 0xff == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BackgroundSubtractorMOG2 배경 제거 (track_bgsub_mog2.py)\n",
    "\n",
    "import numpy as np, cv2\n",
    "\n",
    "cap = cv2.VideoCapture('C:/cdd/street.mp4')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기\n",
    "delay = int(1000/fps)\n",
    "# 배경 제거 객체 생성 --- ①\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # 배경 제거 마스크 계산 --- ②\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('bgsub',fgmask)\n",
    "    if cv2.waitKey(delay) & 0xff == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출처 : https://bkshin.tistory.com/entry/OpenCV-30-%EB%B0%B0%EA%B2%BD-%EC%A0%9C%EA%B1%B0Background-Subtraction?category=1148027"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
